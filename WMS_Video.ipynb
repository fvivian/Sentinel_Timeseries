{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Video with openCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and preprocess the data cubes that were downloaded with the corresponding script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smooth_ALJAWF_AGRICULTURE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "sat = 'S2'\n",
    "layer = 'AGRICULTURE'\n",
    "location = 'ALJAWF'\n",
    "lon = 23.32\n",
    "lat = 24.16\n",
    "if lat >= 0:\n",
    "    filename = f'{sat}_{location}_{layer}_{lon}E_{lat}N'\n",
    "else:\n",
    "    lat = abs(lat)\n",
    "    filename = f'{sat}_{location}_{layer}_{lon}E_{lat}S'\n",
    "outputname=f'smooth_{location}_{layer}'\n",
    "print(outputname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20\r",
      "1/20\r",
      "2/20\r",
      "3/20\r",
      "4/20\r",
      "5/20\r",
      "6/20\r",
      "7/20\r",
      "8/20\r",
      "9/20\r",
      "10/20\r",
      "11/20\r",
      "12/20\r",
      "13/20\r",
      "14/20\r",
      "15/20\r",
      "16/20\r",
      "17/20\r",
      "18/20\r",
      "19/20\r",
      " # days: 20\n"
     ]
    }
   ],
   "source": [
    "date = np.load('Data/'+filename+'_days.npy')\n",
    "data = np.load('Data/'+filename+'.npy')\n",
    "dataF = []\n",
    "dateF = []\n",
    "dummy = None\n",
    "\n",
    "# get rid of double images\n",
    "for i in range(len(date)):\n",
    "    \n",
    "    print(f'{i}/{len(date)}', end='\\r')\n",
    "    # sort out same days\n",
    "    if dummy == date[i]:\n",
    "        pass\n",
    "    else:\n",
    "        dummy = date[i]\n",
    "        dateF.append(date[i])\n",
    "        dataF.append(data[i])\n",
    "\n",
    "print(f' # days: {len(dateF)}')\n",
    "dataF = np.asarray(dataF)\n",
    "\n",
    "# inverse the data from RGB to BGR for openCV\n",
    "try:\n",
    "    dummy = dataF[:,:,:,::-1]\n",
    "    dataInv = dummy[::-1,:,:,:]\n",
    "except:\n",
    "    dataInv = dataF[::-1,:,:]\n",
    "dateInv = dateF[::-1]\n",
    "\n",
    "del(dataF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is needed if there are a lot of images with a high amount of white pixels, i.e. uncomplete scenes. Those images will not be included in the video.\n",
    "\n",
    "\n",
    "The user specifies a percentage of number of pixels out of the total amount of pixels to be a threshold. Every image with a higher content of white pixels than the threshold will be left out of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of images: 20\n",
      "images without white pixels: 19\n"
     ]
    }
   ],
   "source": [
    "# only take scenes with amount of white pixels <= certain threshold\n",
    "filtered = []\n",
    "dateFiltered = []\n",
    "channels = None\n",
    "try:\n",
    "    number, height , width , channels =  dataInv.shape\n",
    "except:\n",
    "    number, height , width =  dataInv.shape\n",
    "\n",
    "threshold = 90 # in percent, 100% means every image will be used.\n",
    "maxWhitePix = height * width * threshold/100\n",
    "\n",
    "if channels != None:\n",
    "    for i in range(len(dataInv)):\n",
    "        if np.where((dataInv[i] >= 254).all(axis=2))[0].size <= maxWhitePix:\n",
    "            filtered.append(dataInv[i])\n",
    "            dateFiltered.append(dateInv[i])\n",
    "\n",
    "else:\n",
    "    for i in range(len(dataInv)):\n",
    "        if np.where((dataInv[i] >= 254))[0].size <= maxWhitePix:\n",
    "            filtered.append(dataInv[i])\n",
    "            dateFiltered.append(dateInv[i])\n",
    "            \n",
    "            \n",
    "print('total number of images:', number)\n",
    "print('images without white pixels:', len(filtered))\n",
    "filtered = np.array(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill areas without data (i.e. areas with three values above 254) with the data from the previous frame (i.e. date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = []\n",
    "datesmooth = []\n",
    "\n",
    "\n",
    "if channels != None:\n",
    "    for i in range(1, len(filtered)):\n",
    "        x, y = np.where((filtered[i] >= 260).all(axis=2))\n",
    "        filtered[i, x, y] = filtered[i-1, x, y]\n",
    "        smooth.append(filtered[i])\n",
    "        datesmooth.append(dateFiltered[i])\n",
    "else:\n",
    "    for i in range(1, len(filtered)):\n",
    "        x, y = np.where(filtered[i] >= 260)\n",
    "        filtered[i, x, y] = filtered[i-1, x, y]\n",
    "        smooth.append(filtered[i])\n",
    "        datesmooth.append(dateFiltered[i])\n",
    "    smooth = np.repeat(np.array(smooth)[:,:,:,np.newaxis], 3, axis=3)\n",
    "smooth = np.array(smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/18\r"
     ]
    }
   ],
   "source": [
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "video = None\n",
    "fps = 25\n",
    "video = cv2.VideoWriter(f'Videos/{outputname}.avi',fourcc, fps, (width,height))\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontSize = 0.5\n",
    "color = (255,255,255)\n",
    "thickness = 1\n",
    "linetype = 0\n",
    "\n",
    "i=0\n",
    "starting = True\n",
    "prev_frame = np.uint8([250])\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    frame = smooth[i]\n",
    "    print(f'{i}/{len(smooth)}', end='\\r')\n",
    "\n",
    "    cv2.rectangle(smooth[i],(0,0),(200,80),(1,1,1), thickness=-1)\n",
    "    # putText(image as array, text as string, position in the image, ..., ..., color as bgr?, ., .)\n",
    "    cv2.putText(smooth[i], datesmooth[i],             (10,25), font, fontSize, color, thickness, linetype)\n",
    "    cv2.putText(smooth[i], f'lon: {lon} / lat: {lat}',(10,40), font, fontSize, color, thickness, linetype)\n",
    "    cv2.putText(smooth[i], f'layer: {layer}',         (10,55), font, fontSize, color, thickness, linetype)\n",
    "    \n",
    "    if starting==True:\n",
    "        prev_frame = frame\n",
    "        starting = False\n",
    "    else:\n",
    "        #video.write(frame)\n",
    "        for l in range(1,20):\n",
    "            weight = (20-l)/20\n",
    "            #get the blended frames in between\n",
    "            mid_frame = cv2.addWeighted(prev_frame,weight,frame,1-weight,0)\n",
    "            video.write(mid_frame)\n",
    "        \n",
    "        for m in range(int(round(fps/2.))):\n",
    "            # add half a second, filled with unprocessed scenes between the blended frames\n",
    "            video.write(frame)\n",
    "        prev_frame = frame\n",
    "    i += 1\n",
    "    if i == len(smooth):\n",
    "        break\n",
    "        \n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
